{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterator\n",
    "from typing import NamedTuple\n",
    "\n",
    "from absl import app\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Set default device to CPU for JAX\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get devices if any\n",
    "devices = jax.devices(\"cpu\")\n",
    "num_devices = len(devices)\n",
    "print(f\"Detected the following devices: {tuple(devices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(NamedTuple):\n",
    "  image: np.ndarray  # [B, H, W, 1]\n",
    "  label: np.ndarray  # [B]\n",
    "\n",
    "class TrainingState(NamedTuple):\n",
    "  params: hk.Params\n",
    "  opt_state: optax.OptState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    split: str,\n",
    "    *,\n",
    "    shuffle: bool,\n",
    "    batch_size: int,\n",
    ") -> Iterator[Batch]:\n",
    "  \"\"\"Loads the MNIST dataset.\"\"\"\n",
    "  ds, ds_info = tfds.load(\"mnist:3.*.*\", split=split, with_info=True)\n",
    "  ds.cache()\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(ds_info.splits[split].num_examples, seed=0)\n",
    "  ds = ds.repeat()\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.map(lambda x: Batch(**x))\n",
    "  return iter(tfds.as_numpy(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    def forward_fn(x: jax.Array) -> jax.Array:\n",
    "        x = x.astype(jnp.float32) / 255.\n",
    "        mlp = hk.Sequential([\n",
    "            hk.Flatten(),\n",
    "            hk.Linear(300), jax.nn.relu,\n",
    "            hk.Linear(100), jax.nn.relu,\n",
    "            hk.Linear(10),\n",
    "        ])\n",
    "        return mlp(x)\n",
    "    \n",
    "    def loss_fn(params, batch):\n",
    "        logits = network.apply(params, batch.image)\n",
    "        labels = jax.nn.one_hot(batch.label, NUM_CLASSES)\n",
    "        loss_value = -jnp.sum(labels * jax.nn.log_softmax(logits))\n",
    "        return loss_value\n",
    "    \n",
    "    @jax.jit\n",
    "    def update(state, batch):\n",
    "        grads = jax.grad(loss_fn)(state.params, batch)\n",
    "        updates, opt_state = optimizer.update(grads, state.opt_state)\n",
    "        params = optax.apply_updates(state.params, updates)\n",
    "\n",
    "        return TrainingState(params, opt_state)\n",
    "    \n",
    "    @jax.jit\n",
    "    def evaluate(state, batch):\n",
    "        logits = network.apply(state.params, batch.image)\n",
    "        predictions = jnp.argmax(logits, axis=-1)\n",
    "        return jnp.mean(predictions == batch.label)\n",
    "\n",
    "    NUM_CLASSES = 10\n",
    "    BATCH_SIZE_TRAIN = 64\n",
    "    BATCH_SIZE_TEST = 10000\n",
    "\n",
    "    print(\"Initializing network..\")\n",
    "    network = hk.without_apply_rng(hk.transform(forward_fn))\n",
    "\n",
    "    print(\"Initializing data..\")\n",
    "    data_train = load_dataset(\"train\", shuffle=True, batch_size=BATCH_SIZE_TRAIN)\n",
    "    data_test = load_dataset(\"test\", shuffle=False, batch_size=BATCH_SIZE_TEST)\n",
    "\n",
    "    print(\"Initializing parameters..\")\n",
    "    params = network.init(jax.random.PRNGKey(seed=0), next(data_train).image)\n",
    "    optimizer = optax.adam(learning_rate=1e-4)\n",
    "    opt_state = optimizer.init(params)\n",
    "    state = TrainingState(params, opt_state)\n",
    "\n",
    "    batch_test = next(data_test)\n",
    "\n",
    "    print(\"Training..\")\n",
    "    NUM_EPOCHS = 5\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"--- Epoch {epoch+1}/{NUM_EPOCHS} ---\")\n",
    "        for i in range(100):\n",
    "            batch = next(data_train)\n",
    "            state = update(state, batch)\n",
    "        \n",
    "        accuracy = evaluate(state, batch_test)\n",
    "        print(\"Accuracy : \", accuracy)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

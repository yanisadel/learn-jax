{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from collections.abc import Iterator\n",
    "from functools import partial\n",
    "\n",
    "from absl import app\n",
    "from dotenv import load_dotenv\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import neptune\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, NamedTuple, Tuple, Callable\n",
    "\n",
    "\n",
    "from learntrix.types import Batch, TrainingState, Metrics\n",
    "\n",
    "# Set default device to CPU for JAX\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get devices if any\n",
    "devices = jax.devices(\"cpu\")\n",
    "num_devices = len(devices)\n",
    "print(f\"Detected the following devices: {tuple(devices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_env_variable(path, name):\n",
    "    load_dotenv(path)\n",
    "    variable = os.getenv(name)\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_project = \"yanisadel/learn-jax\"\n",
    "\n",
    "def run_neptune(path, project):\n",
    "    \"\"\"\n",
    "    path: path of env file with Neptune token\n",
    "    neptune_project: name of the neptune project\n",
    "    \"\"\"\n",
    "    api_token = load_env_variable(path=path, name='NEPTUNE_API_TOKEN')\n",
    "\n",
    "    run = neptune.init_run(\n",
    "        project=neptune_project,\n",
    "        api_token=api_token,\n",
    "    )\n",
    "\n",
    "    return run\n",
    "\n",
    "run = run_neptune(path='./.env', project=neptune_project)\n",
    "\n",
    "params = {\"learning_rate\": 0.001, \"optimizer\": \"Adam\"}\n",
    "run[\"parameters\"] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "    split: str,\n",
    "    *,\n",
    "    shuffle: bool,\n",
    "    batch_size: int,\n",
    ") -> Iterator[Batch]:\n",
    "  \"\"\"Loads the MNIST dataset.\"\"\"\n",
    "  ds, ds_info = tfds.load(\"mnist:3.*.*\", split=split, with_info=True)\n",
    "  ds.cache()\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(ds_info.splits[split].num_examples, seed=0)\n",
    "  ds = ds.repeat()\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.map(lambda x: Batch(**x))\n",
    "  return iter(tfds.as_numpy(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "def forward_fn(x: jax.Array) -> jax.Array:\n",
    "    x = x.astype(jnp.float32) / 255.\n",
    "    mlp = hk.Sequential([\n",
    "        hk.Flatten(),\n",
    "        hk.Linear(300), jax.nn.relu,\n",
    "        hk.Linear(100), jax.nn.relu,\n",
    "        hk.Linear(10),\n",
    "    ])\n",
    "    return mlp(x)\n",
    "\n",
    "def loss_fn(params: hk.Params, batch: NamedTuple, forward_fn: Callable[[jax.Array], jax.Array]) -> Tuple[jax.Array, Metrics]:\n",
    "    logits = forward_fn(params, batch.image)\n",
    "    labels = jax.nn.one_hot(batch.label, NUM_CLASSES)\n",
    "    loss_value = -jnp.sum(labels * jax.nn.log_softmax(logits)) / batch.image.shape[0]\n",
    "\n",
    "    predictions_proba = jax.nn.softmax(logits, axis=-1)\n",
    "    predictions = jnp.argmax(predictions_proba, axis=-1)\n",
    "    accuracy = jnp.mean(predictions == batch.label)\n",
    "    pmean_accuracy = jax.lax.pmean(accuracy, axis_name='batch') # Faudra que je vÃ©rifie quand num_devices > 1\n",
    "\n",
    "    metrics: Metrics = {\n",
    "        \"predictions\": predictions_proba,\n",
    "        \"loss\": loss_value,\n",
    "        \"accuracy\": pmean_accuracy\n",
    "    }\n",
    "\n",
    "    return loss_value, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_forward_fn = hk.without_apply_rng(hk.transform(forward_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_loss_fn = partial(loss_fn,\n",
    "                    forward_fn=_forward_fn.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(forward_fn, loss_fn):\n",
    "    _forward_fn = hk.without_apply_rng(hk.transform(forward_fn))\n",
    "    _loss_fn = partial(loss_fn,\n",
    "                       forward_fn=_forward_fn.apply)\n",
    "    \n",
    "    @partial(jax.pmap, devices=devices, axis_name='batch')\n",
    "    def update(state: NamedTuple, batch: NamedTuple) -> Tuple[NamedTuple, Metrics]:\n",
    "        (_, metrics), grads = jax.value_and_grad(_loss_fn, has_aux=True)(state.params, batch)\n",
    "        grads = jax.lax.pmean(grads, axis_name='batch')\n",
    "        updates, opt_state = optimizer.update(grads, state.opt_state)\n",
    "        params = optax.apply_updates(state.params, updates)\n",
    "\n",
    "        return TrainingState(params, opt_state), metrics\n",
    "    \n",
    "    @partial(jax.pmap, devices=devices, axis_name='batch')\n",
    "    def evaluate(state: NamedTuple, batch: NamedTuple):\n",
    "        _, metrics = _loss_fn(state.params, batch)\n",
    "        # predictions_proba = metrics[\"predictions\"]\n",
    "        # predictions = jnp.argmax(predictions_proba, axis=-1)\n",
    "        # accuracy = jnp.mean(predictions == batch.label)\n",
    "        # pmean_accuracy = jax.lax.pmean(accuracy, axis_name='batch') # log\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    NUM_CLASSES = 10\n",
    "    BATCH_SIZE_TRAIN = 64\n",
    "    BATCH_SIZE_TEST = 10000\n",
    "\n",
    "    print(\"Initializing data..\")\n",
    "    data_train = load_dataset(\"train\", shuffle=True, batch_size=BATCH_SIZE_TRAIN)\n",
    "    data_test = load_dataset(\"test\", shuffle=False, batch_size=BATCH_SIZE_TEST)\n",
    "\n",
    "    print(\"Initializing parameters..\")\n",
    "    params = _forward_fn.init(jax.random.PRNGKey(seed=0), next(data_train).image)\n",
    "    optimizer = optax.adam(learning_rate=1e-4)\n",
    "    opt_state = optimizer.init(params)\n",
    "    state = TrainingState(params, opt_state)\n",
    "\n",
    "    # Replicate parameters and optimizer state across devices\n",
    "    state = jax.device_put_replicated(state, devices)\n",
    "\n",
    "    batch_test = next(data_test)\n",
    "    batch_test = jax.device_put_replicated(batch_test, devices)\n",
    "\n",
    "    all_metrics = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_step\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_step\": [],\n",
    "    }\n",
    "    \n",
    "    print(\"Training..\")\n",
    "    NUM_STEPS = 100\n",
    "    validation_step = 10\n",
    "\n",
    "    for step in tqdm(range(1, NUM_STEPS+1)):\n",
    "        batch = next(data_train)\n",
    "        # batch = jax.tree.map(lambda x: x.reshape((num_devices, -1) + x.shape[1:]), batch)\n",
    "        batch = jax.device_put_replicated(batch, devices)\n",
    "        state, metrics = update(state, batch)\n",
    "        \n",
    "        train_loss = jax.device_get(metrics[\"loss\"]).mean()\n",
    "        train_accuracy = jax.device_get(metrics[\"accuracy\"]).mean()\n",
    "\n",
    "        run[\"train/loss\"].log(train_loss, step=step)\n",
    "        run[\"train/accuracy\"].log(train_accuracy, step=step)\n",
    "\n",
    "        all_metrics[\"train_loss\"].append(train_loss)\n",
    "        all_metrics[\"train_acc\"].append(train_accuracy)\n",
    "        all_metrics[\"train_step\"].append(step)\n",
    "\n",
    "        if step % validation_step == 0:\n",
    "            # Evaluate on test batch\n",
    "            \n",
    "            # batch_test = jax.tree.map(lambda x: x.reshape((num_devices, -1) + x.shape[1:]), batch_test)\n",
    "            metrics = evaluate(state, batch_test)\n",
    "            test_loss = jax.device_get(metrics[\"loss\"]).mean()\n",
    "            test_accuracy = jax.device_get(metrics[\"accuracy\"]).mean()\n",
    "\n",
    "            run[\"test/loss\"].log(test_loss, step=step)\n",
    "            run[\"test/accuracy\"].log(test_accuracy, step=step)\n",
    "\n",
    "            all_metrics[\"val_loss\"].append(test_loss)\n",
    "            all_metrics[\"val_acc\"].append(test_accuracy)\n",
    "            all_metrics[\"val_step\"].append(step)\n",
    "\n",
    "    run.stop()\n",
    "\n",
    "main(forward_fn, _loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

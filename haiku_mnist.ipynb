{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from collections.abc import Iterator\n",
    "from functools import partial\n",
    "\n",
    "from absl import app\n",
    "from dotenv import load_dotenv\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import neptune\n",
    "import numpy as np\n",
    "import optax\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, NamedTuple, Tuple, Callable\n",
    "\n",
    "from learntrix.datalaoders.computer_vision.mnist import load_mnist_dataset\n",
    "\n",
    "from learntrix.types import Batch, TrainingState, Metrics\n",
    "\n",
    "# Set default device to CPU for JAX\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get devices if any\n",
    "devices = jax.devices(\"cpu\")\n",
    "num_devices = len(devices)\n",
    "print(f\"Detected the following devices: {tuple(devices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_env_variable(path, name):\n",
    "    load_dotenv(path)\n",
    "    variable = os.getenv(name)\n",
    "    return variable\n",
    "\n",
    "def run_neptune(path, project):\n",
    "    \"\"\"\n",
    "    path: path of env file with Neptune token\n",
    "    neptune_project: name of the neptune project\n",
    "    \"\"\"\n",
    "    api_token = load_env_variable(path=path, name='NEPTUNE_API_TOKEN')\n",
    "\n",
    "    run = neptune.init_run(\n",
    "        project=project,\n",
    "        api_token=api_token,\n",
    "    )\n",
    "\n",
    "    return run\n",
    "\n",
    "run = run_neptune(path='./.env', project=\"yanisadel/learn-jax\")\n",
    "\n",
    "params = {\"learning_rate\": 0.001, \"optimizer\": \"Adam\"}\n",
    "run[\"parameters\"] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_TRAIN = 64\n",
    "BATCH_SIZE_TEST = 10000\n",
    "\n",
    "data_train = load_mnist_dataset(\n",
    "    \"train\",\n",
    "    shuffle=True, \n",
    "    batch_size=BATCH_SIZE_TRAIN\n",
    "    )\n",
    "data_test = load_mnist_dataset(\n",
    "    \"test\",\n",
    "    shuffle=False, \n",
    "    batch_size=BATCH_SIZE_TEST\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "def forward_fn(x: jax.Array) -> jax.Array:\n",
    "    x = x.astype(jnp.float32) / 255.\n",
    "    mlp = hk.Sequential([\n",
    "        hk.Flatten(),\n",
    "        hk.Linear(300), jax.nn.relu,\n",
    "        hk.Linear(100), jax.nn.relu,\n",
    "        hk.Linear(10),\n",
    "    ])\n",
    "    return mlp(x)\n",
    "\n",
    "def loss_fn(params: hk.Params, batch: NamedTuple, forward_fn: Callable[[jax.Array], jax.Array]) -> Tuple[jax.Array, Metrics]:\n",
    "    logits = forward_fn(params, batch.image)\n",
    "    labels = jax.nn.one_hot(batch.label, NUM_CLASSES)\n",
    "    loss_value = -jnp.sum(labels * jax.nn.log_softmax(logits)) / batch.image.shape[0]\n",
    "\n",
    "    predictions_proba = jax.nn.softmax(logits, axis=-1)\n",
    "    predictions = jnp.argmax(predictions_proba, axis=-1)\n",
    "    accuracy = jnp.mean(predictions == batch.label)\n",
    "    pmean_accuracy = jax.lax.pmean(accuracy, axis_name='batch') # Faudra que je vÃ©rifie quand num_devices > 1\n",
    "\n",
    "    metrics: Metrics = {\n",
    "        \"predictions\": predictions_proba,\n",
    "        \"loss\": loss_value,\n",
    "        \"accuracy\": pmean_accuracy\n",
    "    }\n",
    "\n",
    "    return loss_value, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, forward_fn, loss_fn, optimizer, num_classes):\n",
    "        self._forward_fn = hk.without_apply_rng(hk.transform(forward_fn))\n",
    "        self._loss_fn = partial(loss_fn,\n",
    "                                forward_fn=self._forward_fn.apply)\n",
    "        self._optimizer = optimizer\n",
    "        self._num_classes = num_classes\n",
    "        \n",
    "    \n",
    "    def init(self, random_key, x):\n",
    "        params = self._forward_fn.init(random_key, x)\n",
    "        opt_state = self._optimizer.init(params)\n",
    "\n",
    "        return TrainingState(params, opt_state)\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=0)\n",
    "    def update(self, state: TrainingState, batch: Batch) -> Tuple[TrainingState, Metrics]:\n",
    "        (_, metrics), grads = jax.value_and_grad(self._loss_fn, has_aux=True)(state.params, batch)\n",
    "        grads = jax.lax.pmean(grads, axis_name='batch')\n",
    "        updates, opt_state = self._optimizer.update(grads, state.opt_state)\n",
    "        params = optax.apply_updates(state.params, updates)\n",
    "\n",
    "        return TrainingState(params, opt_state), metrics\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=0)\n",
    "    def evaluate(self, state: TrainingState, batch: Batch):\n",
    "        _, metrics = self._loss_fn(state.params, batch)\n",
    "        # predictions_proba = metrics[\"predictions\"]\n",
    "        # predictions = jnp.argmax(predictions_proba, axis=-1)\n",
    "        # accuracy = jnp.mean(predictions == batch.label)\n",
    "        # pmean_accuracy = jax.lax.pmean(accuracy, axis_name='batch') #\n",
    "\n",
    "        return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    forward_fn=forward_fn,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optax.adam(learning_rate=1e-3),\n",
    "    num_classes=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_state = trainer.init(\n",
    "    jax.random.PRNGKey(0), \n",
    "    x=jnp.ones(shape=(32, 28, 28, 1))\n",
    "    )\n",
    "training_state = jax.device_put_replicated(training_state, devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test = next(data_test)\n",
    "batch_test = jax.device_put_replicated(batch_test, devices)\n",
    "\n",
    "all_metrics = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"train_step\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": [],\n",
    "    \"val_step\": [],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_STEPS = 100\n",
    "validation_step = 10\n",
    "\n",
    "update = trainer.update\n",
    "\n",
    "for step in tqdm(range(1, NUM_STEPS+1)):\n",
    "    batch = next(data_train)\n",
    "    # batch = jax.tree.map(lambda x: x.reshape((num_devices, -1) + x.shape[1:]), batch)\n",
    "    batch = jax.device_put_replicated(batch, devices)\n",
    "\n",
    "    training_state, metrics = jax.pmap(update, devices=devices, axis_name='batch')(training_state, batch)\n",
    "    \n",
    "    train_loss = jax.device_get(metrics[\"loss\"]).mean()\n",
    "    train_accuracy = jax.device_get(metrics[\"accuracy\"]).mean()\n",
    "\n",
    "    run[\"train/loss\"].log(train_loss, step=step)\n",
    "    run[\"train/accuracy\"].log(train_accuracy, step=step)\n",
    "\n",
    "    all_metrics[\"train_loss\"].append(train_loss)\n",
    "    all_metrics[\"train_acc\"].append(train_accuracy)\n",
    "    all_metrics[\"train_step\"].append(step)\n",
    "\n",
    "    if step % validation_step == 0:\n",
    "        # Evaluate on test batch\n",
    "        \n",
    "        # batch_test = jax.tree.map(lambda x: x.reshape((num_devices, -1) + x.shape[1:]), batch_test)\n",
    "        metrics = jax.pmap(trainer.evaluate, devices=devices, axis_name='batch')(training_state, batch_test)\n",
    "        test_loss = jax.device_get(metrics[\"loss\"]).mean()\n",
    "        test_accuracy = jax.device_get(metrics[\"accuracy\"]).mean()\n",
    "\n",
    "        run[\"test/loss\"].log(test_loss, step=step)\n",
    "        run[\"test/accuracy\"].log(test_accuracy, step=step)\n",
    "\n",
    "        all_metrics[\"val_loss\"].append(test_loss)\n",
    "        all_metrics[\"val_acc\"].append(test_accuracy)\n",
    "        all_metrics[\"val_step\"].append(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
